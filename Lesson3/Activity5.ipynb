{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity 1 : Developing end to end Text Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following methods to classify the Wikipedia comments (classes: toxic or not): <br>\n",
    "1) Logistic Regression <br>\n",
    "2) Random Forest <br>\n",
    "3) XG-Boost <br>\n",
    "\n",
    "Which tokens (i.e. words) seem to be important predictors while using Random Forest and XG-Boost <br>\n",
    "\n",
    "Divide the data into training and validation set. Evaluate the models developed on the hold out validation set using parameters like Confusion matrix, Accuracy, Precision, Recall, F1. Plot ROC curve and find area under it.\n",
    "\n",
    "Data source: The data has been adapted from https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data\n",
    "The dataset under CC0, with the underlying comment text being governed by Wikipedia's CC-SA-3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pylab import *\n",
    "import nltk\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import accuracy_score,roc_curve,classification_report,confusion_matrix,precision_recall_curve,auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_ch3/train_comment_small.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_model(model_type, X_train, y_train, X_valid):\n",
    "    model = model_type.fit(X_train,y_train)\n",
    "    predicted_labels = model.predict(X_valid)\n",
    "    predicted_probab = model.predict_proba(X_valid)[:,1]\n",
    "    return [predicted_labels,predicted_probab, model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(actual_values, predicted_values, predicted_probabilities):\n",
    "    cfn_mat = confusion_matrix(actual_values,predicted_values)\n",
    "    print(\"confusion matrix: \\n\",cfn_mat)\n",
    "    print(\"\\naccuracy: \",accuracy_score(actual_values,predicted_values))\n",
    "    print(\"\\nclassification report: \\n\", classification_report(actual_values,predicted_values))\n",
    "    fpr,tpr,threshold=roc_curve(actual_values, predicted_probabilities)\n",
    "    print ('\\nArea under ROC curve for validation set:', auc(fpr,tpr))\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    ax.plot(fpr,tpr,label='Validation set AUC')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    ax.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "#adding individual printable characters to list of wtop words so that they get renoved along with the stopwords\n",
    "stop_words = stop_words + list(string.printable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cleaned_comment_text'] = data['comment_text'].apply(\\\n",
    "lambda x : ' '.join([lemmatizer.lemmatize(word.lower()) \\\n",
    "    for word in word_tokenize(re.sub(r'([^\\s\\w]|_)+', ' ', str(x))) if word.lower() not in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model = TfidfVectorizer(max_features=500)\n",
    "tfidf_df = pd.DataFrame(tfidf_model.fit_transform(data['cleaned_comment_text']).todense())\n",
    "tfidf_df.columns = sorted(tfidf_model.vocabulary_)\n",
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(tfidf_df, data['toxic'], \\\n",
    "                                                      test_size=0.2, random_state=42,stratify = data['toxic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "results = clf_model(logreg, X_train, y_train, X_valid)\n",
    "model_evaluation(y_valid, results[0], results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "rfc = RandomForestClassifier(n_estimators=20,max_depth=4,max_features='sqrt',random_state=1)\n",
    "results = clf_model(rfc, X_train, y_train, X_valid)\n",
    "model_evaluation(y_valid, results[0], results[1])\n",
    "model_rfc = results[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_importances = pd.DataFrame({'word':X_train.columns,'importance':model_rfc.feature_importances_})\n",
    "word_importances.sort_values('importance', ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG-Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb_clf=XGBClassifier(n_estimators=20,learning_rate=0.03,max_depth=5,subsample=0.6,colsample_bytree= 0.6,reg_alpha= 10,seed=42)\n",
    "results = clf_model(xgb_clf, X_train, y_train, X_valid)\n",
    "model_evaluation(y_valid, results[0], results[1])\n",
    "model_xgb = results[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_importances = pd.DataFrame({'word':X_train.columns,'importance':model_xgb.feature_importances_})\n",
    "word_importances.sort_values('importance', ascending = False).head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
